{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center><h1> Data for Visualization </center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the code for preparing some data for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS) #Set of English Stopwords\n",
    "\n",
    "import numpy as npy\n",
    "from PIL import Image\n",
    "\n",
    "maskArray = npy.array(Image.open(\"mask.png\")) # Twitter Logo as a mask for wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant files\n",
    "\n",
    "sent_df = pd.read_csv(\"Processed Data.csv\",sep='\\t')\n",
    "topic_df = pd.read_csv(\"Topic Modelled Data.csv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_df = sent_df.loc[:,['date','time','id']]\n",
    "df = pd.merge(left=relevant_df, right=topic_df, left_on='id', right_on='id') #Merge the dataframe with respect to ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>topic_data</th>\n",
       "      <th>topic_perc_contrib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360804</th>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>18:02:57</td>\n",
       "      <td>1258094919266099200</td>\n",
       "      <td>USER_MENTION USER_MENTION yet updated today co...</td>\n",
       "      <td>case, people, india, virus, today, government,...</td>\n",
       "      <td>0.983669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420724</th>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>16:04:46</td>\n",
       "      <td>1262051444766789632</td>\n",
       "      <td>eye china india back push probe covid19 origin...</td>\n",
       "      <td>help, u, india, virus, people, fight, sir, man...</td>\n",
       "      <td>0.996122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531059</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>18:53:50</td>\n",
       "      <td>1271153686610358275</td>\n",
       "      <td>person much illness getting corona getting awa...</td>\n",
       "      <td>one, people, time, please, go, u, need, also, ...</td>\n",
       "      <td>0.990418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date      time                   id  \\\n",
       "360804  2020-05-06  18:02:57  1258094919266099200   \n",
       "420724  2020-05-17  16:04:46  1262051444766789632   \n",
       "531059  2020-06-11  18:53:50  1271153686610358275   \n",
       "\n",
       "                                           processed_text  \\\n",
       "360804  USER_MENTION USER_MENTION yet updated today co...   \n",
       "420724  eye china india back push probe covid19 origin...   \n",
       "531059  person much illness getting corona getting awa...   \n",
       "\n",
       "                                               topic_data  topic_perc_contrib  \n",
       "360804  case, people, india, virus, today, government,...            0.983669  \n",
       "420724  help, u, india, virus, people, fight, sir, man...            0.996122  \n",
       "531059  one, people, time, please, go, u, need, also, ...            0.990418  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3) #Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop irrevelant data\n",
    "\n",
    "df.drop(['id','topic_perc_contrib','time','processed_text'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf=df.groupby('date')['topic_data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>topic_data</th>\n",
       "      <th>topic_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>people, india, virus, one, govt, please, day, ...</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>u, day, may, india, due, get, people, n, sir, ...</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>one, people, time, please, go, u, need, also, ...</td>\n",
       "      <td>1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>india, people, patient, like, day, sir, delhi,...</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>people, u, please, sir, time, government, figh...</td>\n",
       "      <td>1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>people, u, please, sir, time, government, figh...</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>one, people, time, please, go, u, need, also, ...</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>govt, home, people, one, fight, india, work, c...</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>time, day, india, virus, case, world, u, count...</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>help, u, india, virus, people, fight, sir, man...</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                         topic_data  \\\n",
       "0    2020-03-25  people, india, virus, one, govt, please, day, ...   \n",
       "1    2020-03-25  u, day, may, india, due, get, people, n, sir, ...   \n",
       "2    2020-03-25  one, people, time, please, go, u, need, also, ...   \n",
       "3    2020-03-25  india, people, patient, like, day, sir, delhi,...   \n",
       "4    2020-03-25  people, u, please, sir, time, government, figh...   \n",
       "..          ...                                                ...   \n",
       "815  2020-06-14  people, u, please, sir, time, government, figh...   \n",
       "816  2020-06-14  one, people, time, please, go, u, need, also, ...   \n",
       "817  2020-06-14  govt, home, people, one, fight, india, work, c...   \n",
       "818  2020-06-14  time, day, india, virus, case, world, u, count...   \n",
       "819  2020-06-14  help, u, india, virus, people, fight, sir, man...   \n",
       "\n",
       "     topic_count  \n",
       "0           1694  \n",
       "1           1509  \n",
       "2           1329  \n",
       "3           1282  \n",
       "4           1221  \n",
       "..           ...  \n",
       "815         1201  \n",
       "816         1168  \n",
       "817         1077  \n",
       "818         1025  \n",
       "819          863  \n",
       "\n",
       "[820 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group the data with respect to date and count the number of topics\n",
    "\n",
    "df=df.groupby('date')['topic_data'].value_counts()\n",
    "df = pd.DataFrame(df)\n",
    "df.rename(columns={'topic_data': 'topic_count'},inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into different lockdown phases and save the data\n",
    "\n",
    "lockdown1 = df[(df['date'] >= '2020-03-25') & (df['date'] <= '2020-04-14')]\n",
    "lockdown1 = lockdown1.groupby('topic_data').sum()\n",
    "lockdown1.reset_index(inplace=True)\n",
    "lockdown1.sort_values(by='topic_count',inplace=True,ascending=False)\n",
    "lockdown1.insert(0, \"Phase\", \"LD1\") \n",
    "\n",
    "lockdown2 = df[(df['date'] >= '2020-04-15') & (df['date'] <= '2020-05-03')]\n",
    "lockdown2 = lockdown2.groupby('topic_data').sum()\n",
    "lockdown2.reset_index(inplace=True)\n",
    "lockdown2.sort_values(by='topic_count',inplace=True,ascending=False)\n",
    "lockdown2.insert(0, \"Phase\", \"LD2\") \n",
    "\n",
    "lockdown3 = df[(df['date'] >= '2020-05-04') & (df['date'] <= '2020-05-17')]\n",
    "lockdown3 = lockdown3.groupby('topic_data').sum()\n",
    "lockdown3.reset_index(inplace=True)\n",
    "lockdown3.sort_values(by='topic_count',inplace=True,ascending=False)\n",
    "lockdown3.insert(0, \"Phase\", \"LD3\") \n",
    "\n",
    "lockdown4 = df[(df['date'] >= '2020-05-18') & (df['date'] <= '2020-05-31')]\n",
    "lockdown4 = lockdown4.groupby('topic_data').sum()\n",
    "lockdown4.reset_index(inplace=True)\n",
    "lockdown4.sort_values(by='topic_count',inplace=True,ascending=False)\n",
    "lockdown4.insert(0, \"Phase\", \"LD4\") \n",
    "\n",
    "unlock1 = df[(df['date'] >= '2020-06-01') & (df['date'] <= '2020-06-14')]\n",
    "unlock1 = unlock1.groupby('topic_data').sum()\n",
    "unlock1.reset_index(inplace=True)\n",
    "unlock1.sort_values(by='topic_count',inplace=True,ascending=False)\n",
    "unlock1.insert(0, \"Phase\", \"Unlock1\") \n",
    "\n",
    "combined_df = pd.concat([lockdown1,lockdown2,lockdown3,lockdown4,unlock1],ignore_index=True)\n",
    "combined_df.to_csv(\"Topic data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199578</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>#Lockdownextention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>#Lockdown21 #testings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31682</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>#21daysLockdownIndia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date               hashtags\n",
       "199578  2020-04-14     #Lockdownextention\n",
       "635     2020-03-25  #Lockdown21 #testings\n",
       "31682   2020-03-27   #21daysLockdownIndia"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "hash_df = sent_df.loc[:,['date','hashtags']]\n",
    "hash_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into different lockdown phases, find the top 10 hashtags and save the data\n",
    "\n",
    "lockdown1 = hash_df[(hash_df['date'] >= '2020-03-25') & (hash_df['date'] <= '2020-04-14')]\n",
    "lockdown1 = pd.DataFrame(lockdown1['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "lockdown1.reset_index(inplace=True)\n",
    "lockdown1.insert(0, \"Phase\", \"LD1\")\n",
    "lockdown1.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "lockdown2 = hash_df[(hash_df['date'] >= '2020-04-15') & (hash_df['date'] <= '2020-05-03')]\n",
    "lockdown2 = pd.DataFrame(lockdown2['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "lockdown2.reset_index(inplace=True)\n",
    "lockdown2.insert(0, \"Phase\", \"LD2\")\n",
    "lockdown2.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "lockdown3 = hash_df[(hash_df['date'] >= '2020-05-04') & (hash_df['date'] <= '2020-05-17')]\n",
    "lockdown3 = pd.DataFrame(lockdown3['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "lockdown3.reset_index(inplace=True)\n",
    "lockdown3.insert(0, \"Phase\", \"LD3\")\n",
    "lockdown3.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "lockdown4 = hash_df[(hash_df['date'] >= '2020-05-18') & (hash_df['date'] <= '2020-05-31')]\n",
    "lockdown4 = pd.DataFrame(lockdown4['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "lockdown4.reset_index(inplace=True)\n",
    "lockdown4.insert(0, \"Phase\", \"LD4\")\n",
    "lockdown4.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "unlock1 = hash_df[(hash_df['date'] >= '2020-06-01') & (hash_df['date'] <= '2020-06-14')]\n",
    "unlock1 = pd.DataFrame(unlock1['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "unlock1.reset_index(inplace=True)\n",
    "unlock1.insert(0, \"Phase\", \"Unlock1\")\n",
    "unlock1.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "combined_df = pd.concat([lockdown1,lockdown2,lockdown3,lockdown4,unlock1],ignore_index=True)\n",
    "combined_df.to_csv(\"Hashtag data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sadness</th>\n",
       "      <th>confident</th>\n",
       "      <th>joy</th>\n",
       "      <th>analytical</th>\n",
       "      <th>anger</th>\n",
       "      <th>tentative</th>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  sadness  confident  joy  analytical  anger  tentative  fear\n",
       "2032  2020-06-14      1.0        NaN  NaN         1.0    NaN        1.0   NaN\n",
       "2006  2020-06-11      NaN        NaN  NaN         1.0    NaN        1.0   NaN\n",
       "1371  2020-05-17      NaN        NaN  NaN         1.0    NaN        NaN   NaN"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data and remove unnecessary columns\n",
    "\n",
    "tone_df = pd.read_csv(\"Sentiment Data.csv\",sep='\\t')\n",
    "tone_df = tone_df.loc[:,['date','sadness','confident','joy','analytical','anger','tentative','fear']]\n",
    "tone_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into different lockdown phases and save the data\n",
    "\n",
    "lockdown1 = tone_df[(tone_df['date'] >= '2020-03-25') & (tone_df['date'] <= '2020-04-14')]\n",
    "lockdown1 = pd.DataFrame(lockdown1.sum())\n",
    "lockdown1 = lockdown1.T\n",
    "lockdown1.drop(['date'],axis=1,inplace=True)\n",
    "lockdown1.insert(0,\"Phase\",\"LD1\")\n",
    "\n",
    "lockdown2 = tone_df[(tone_df['date'] >= '2020-04-15') & (tone_df['date'] <= '2020-05-03')]\n",
    "lockdown2 = pd.DataFrame(lockdown2.sum())\n",
    "lockdown2 = lockdown2.T\n",
    "lockdown2.drop(['date'],axis=1,inplace=True)\n",
    "lockdown2.insert(0,\"Phase\",\"LD2\")\n",
    "\n",
    "lockdown3 = tone_df[(tone_df['date'] >= '2020-05-04') & (tone_df['date'] <= '2020-05-17')]\n",
    "lockdown3 = pd.DataFrame(lockdown3.sum())\n",
    "lockdown3 = lockdown3.T\n",
    "lockdown3.drop(['date'],axis=1,inplace=True)\n",
    "lockdown3.insert(0,\"Phase\",\"LD3\")\n",
    "\n",
    "lockdown4 = tone_df[(tone_df['date'] >= '2020-05-18') & (tone_df['date'] <= '2020-05-31')]\n",
    "lockdown4 = pd.DataFrame(lockdown4.sum())\n",
    "lockdown4 = lockdown4.T\n",
    "lockdown4.drop(['date'],axis=1,inplace=True)\n",
    "lockdown4.insert(0,\"Phase\",\"LD4\")\n",
    "\n",
    "unlock1 = tone_df[(tone_df['date'] >= '2020-06-01') & (tone_df['date'] <= '2020-06-14')]\n",
    "unlock1 = pd.DataFrame(unlock1.sum())\n",
    "unlock1 = unlock1.T\n",
    "unlock1.drop(['date'],axis=1,inplace=True)\n",
    "unlock1.insert(0,\"Phase\",\"Unlock1\")\n",
    "\n",
    "combined_df = pd.concat([lockdown1,lockdown2,lockdown3,lockdown4,unlock1],ignore_index=True)\n",
    "combined_df = combined_df.melt(\"Phase\")\n",
    "combined_df.rename({\"variable\":\"Tone\",\"value\":\"Value\"},axis=1,inplace=True)\n",
    "combined_df = combined_df.sort_values(by=\"Phase\")\n",
    "combined_df.to_csv(\"Tone data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>username</th>\n",
       "      <th>to</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331216</th>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>07:20:41</td>\n",
       "      <td>prashantkarkera</td>\n",
       "      <td>EktaWorld</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know what you are rejoicing about when...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#poorcustomercare #ektaparkville #anilkapoor #...</td>\n",
       "      <td>1256483733831639040</td>\n",
       "      <td>https://twitter.com/prashantkarkera/status/125...</td>\n",
       "      <td>dont know rejoicing existing customer given po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293540</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>14:25:33</td>\n",
       "      <td>MannuDas18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>#Help_Them There is a lot of merit in satisfyi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Help_Them</td>\n",
       "      <td>1254416327894278144</td>\n",
       "      <td>https://twitter.com/MannuDas18/status/12544163...</td>\n",
       "      <td>help_them lot merit satisfying hunger hungry d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41792</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>14:02:13</td>\n",
       "      <td>helena_kolesnyk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fuck off corona #joke #besafe #CoronavirusPand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#joke #besafe #CoronavirusPandemic</td>\n",
       "      <td>1243901209259343872</td>\n",
       "      <td>https://twitter.com/helena_kolesnyk/status/124...</td>\n",
       "      <td>fuck corona joke besafe coronaviruspandemic pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date      time         username         to  replies  retweets  \\\n",
       "331216  2020-05-02  07:20:41  prashantkarkera  EktaWorld        0         0   \n",
       "293540  2020-04-26  14:25:33       MannuDas18        NaN        0         1   \n",
       "41792   2020-03-28  14:02:13  helena_kolesnyk        NaN        1         0   \n",
       "\n",
       "        favorites                                               text mentions  \\\n",
       "331216          0  I don't know what you are rejoicing about when...      NaN   \n",
       "293540          1  #Help_Them There is a lot of merit in satisfyi...      NaN   \n",
       "41792           2  Fuck off corona #joke #besafe #CoronavirusPand...      NaN   \n",
       "\n",
       "                                                 hashtags  \\\n",
       "331216  #poorcustomercare #ektaparkville #anilkapoor #...   \n",
       "293540                                         #Help_Them   \n",
       "41792                  #joke #besafe #CoronavirusPandemic   \n",
       "\n",
       "                         id  \\\n",
       "331216  1256483733831639040   \n",
       "293540  1254416327894278144   \n",
       "41792   1243901209259343872   \n",
       "\n",
       "                                                permalink  \\\n",
       "331216  https://twitter.com/prashantkarkera/status/125...   \n",
       "293540  https://twitter.com/MannuDas18/status/12544163...   \n",
       "41792   https://twitter.com/helena_kolesnyk/status/124...   \n",
       "\n",
       "                                           processed_text  \n",
       "331216  dont know rejoicing existing customer given po...  \n",
       "293540  help_them lot merit satisfying hunger hungry d...  \n",
       "41792   fuck corona joke besafe coronaviruspandemic pu...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "\n",
    "df = pd.read_csv(\"Processed Data.csv\",sep='\\t')\n",
    "df['processed_text']=df['processed_text'].astype(str)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>yeah missing freedom life covid19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>contribute cm relief fund help delhi govt figh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>bhai assalamualaikum possible please call bhai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>bold adress nation activity banned except esse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>please understand important stay home responsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582685</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582686</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582687</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>italy face two new coronavirus outbreak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582688</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>india become top none modi reign india became ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582689</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>tokyo report jump coronavirus case many linked...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582690 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                                     processed_text\n",
       "0       2020-03-25                  yeah missing freedom life covid19\n",
       "1       2020-03-25  contribute cm relief fund help delhi govt figh...\n",
       "2       2020-03-25  bhai assalamualaikum possible please call bhai...\n",
       "3       2020-03-25  bold adress nation activity banned except esse...\n",
       "4       2020-03-25  please understand important stay home responsi...\n",
       "...            ...                                                ...\n",
       "582685  2020-06-14                                                URL\n",
       "582686  2020-06-14                                              covid\n",
       "582687  2020-06-14            italy face two new coronavirus outbreak\n",
       "582688  2020-06-14  india become top none modi reign india became ...\n",
       "582689  2020-06-14  tokyo report jump coronavirus case many linked...\n",
       "\n",
       "[582690 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary data\n",
    "\n",
    "cloud_df = df.loc[:,['date','processed_text']]\n",
    "cloud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1cfb2c172b0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data into different lockdown phases, generate wordcloud and save the data\n",
    "\n",
    "lockdown1 = cloud_df[(cloud_df['date'] >= '2020-03-25') & (cloud_df['date'] <= '2020-04-14')]\n",
    "text = []\n",
    "for item in lockdown1['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "lockdown1text = \" \".join(string)\n",
    "lockdown1cloud = WordCloud(background_color = \"white\",stopwords = stopwords,mask = maskArray)\n",
    "lockdown1cloud.generate(lockdown1text)\n",
    "lockdown1cloud.to_file(\"Lockdown1 cloud.png\")\n",
    "\n",
    "lockdown2 = cloud_df[(cloud_df['date'] >= '2020-04-15') & (cloud_df['date'] <= '2020-05-03')]\n",
    "text = []\n",
    "for item in lockdown2['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "lockdown2text = \" \".join(string)\n",
    "lockdown2cloud = WordCloud(background_color = \"white\",stopwords = stopwords,mask = maskArray)\n",
    "lockdown2cloud.generate(lockdown2text)\n",
    "lockdown2cloud.to_file(\"Lockdown2 cloud.png\")\n",
    "\n",
    "lockdown3 = cloud_df[(cloud_df['date'] >= '2020-05-04') & (cloud_df['date'] <= '2020-05-17')]\n",
    "text = []\n",
    "for item in lockdown3['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "lockdown3text = \" \".join(string)\n",
    "lockdown3cloud = WordCloud(background_color = \"white\",stopwords = stopwords,mask = maskArray)\n",
    "lockdown3cloud.generate(lockdown3text)\n",
    "lockdown3cloud.to_file(\"Lockdown3 cloud.png\")\n",
    "\n",
    "lockdown4 = cloud_df[(cloud_df['date'] >= '2020-05-18') & (cloud_df['date'] <= '2020-05-31')]\n",
    "text = []\n",
    "for item in lockdown4['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "lockdown4text = \" \".join(string)\n",
    "lockdown4cloud = WordCloud(background_color = \"white\",stopwords = stopwords,mask = maskArray)\n",
    "lockdown4cloud.generate(lockdown4text)\n",
    "lockdown4cloud.to_file(\"Lockdown4 cloud.png\")\n",
    "\n",
    "unlock1 = cloud_df[(cloud_df['date'] >= '2020-06-01') & (cloud_df['date'] <= '2020-06-14')]\n",
    "text = []\n",
    "for item in unlock1['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "unlock1text = \" \".join(string)\n",
    "unlock1cloud = WordCloud(background_color = \"white\",stopwords = stopwords,mask = maskArray)\n",
    "unlock1cloud.generate(unlock1text)\n",
    "unlock1cloud.to_file(\"Unlock1 cloud.png\")\n",
    "\n",
    "#General Data\n",
    "\n",
    "text = []\n",
    "for item in cloud_df['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "generaltext = \" \".join(string)\n",
    "generalcloud = WordCloud(background_color = \"white\",stopwords = stopwords,mask = maskArray)\n",
    "generalcloud.generate(generaltext)\n",
    "generalcloud.to_file(\"General cloud.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
